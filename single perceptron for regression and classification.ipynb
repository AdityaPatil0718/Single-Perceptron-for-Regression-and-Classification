{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step_function(x):\n",
    "    return np.where(x > 0, 1, 0)\n",
    "\n",
    "def sin_lay_perc(inputs, targets, learning_rate=0.1, epochs=800):\n",
    "    weights = np.random.rand(inputs.shape[1])\n",
    "    bias = np.random.rand()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        for input_data, target in zip(inputs, targets):\n",
    "            weighted_sum = np.dot(input_data, weights) + bias\n",
    "            output = step_function(weighted_sum)\n",
    "            \n",
    "            #update weights and bias using the perceptron learning rule\n",
    "            error = target - output\n",
    "            weights += learning_rate * error * input_data\n",
    "            bias += learning_rate * error\n",
    "\n",
    "    def predict(input_data):\n",
    "        return step_function(np.dot(input_data, weights) + bias)\n",
    "        \n",
    "    def evaluate(inputs, targets):\n",
    "        correct_predictions = sum(predict(input_data) == target for input_data, target in zip(inputs, targets))\n",
    "        accuracy = correct_predictions / len(targets)\n",
    "        return accuracy\n",
    "\n",
    "    return predict, evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XOR Accuracy: 50.0%\n",
      "[0 0] -> 1\n",
      "[0 1] -> 1\n",
      "[1 0] -> 0\n",
      "[1 1] -> 0\n",
      "XNOR Accuracy: 25.0%\n",
      "[0 0] -> 0\n",
      "[0 1] -> 1\n",
      "[1 0] -> 1\n",
      "[1 1] -> 1\n"
     ]
    }
   ],
   "source": [
    "#XOR n XNOR dataset\n",
    "xor_inputs = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "xor_target = np.array([0,1,1,0])\n",
    "\n",
    "#XNOR\n",
    "xnor_inputs = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "xnor_target = np.array([1,0,0,1])\n",
    "\n",
    "#create n train slp for xor\n",
    "xor_predict, xor_evaluate = sin_lay_perc(xor_inputs, xor_target)\n",
    "xor_accuracy = xor_evaluate(xor_inputs, xor_target)\n",
    "\n",
    "xnor_predict, xnor_evaluate = sin_lay_perc(xnor_inputs, xnor_target)\n",
    "xnor_accuracy = xnor_evaluate(xnor_inputs, xnor_target)\n",
    "\n",
    "print(f\"XOR Accuracy: {xor_accuracy * 100}%\")\n",
    "for input_data in xor_inputs:\n",
    "    prediction = xor_predict(input_data)\n",
    "    print(f\"{input_data} -> {prediction}\")\n",
    "\n",
    "print(f\"XNOR Accuracy: {xnor_accuracy * 100}%\")\n",
    "for input_data in xnor_inputs:\n",
    "    prediction = xnor_predict(input_data)\n",
    "    print(f\"{input_data} -> {prediction}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_activation(x):\n",
    "    return x\n",
    "\n",
    "def SLP(inputs, targets, learning_rate = 0.1, epochs = 800):\n",
    "    weights = np.random.rand(inputs.shape[1])\n",
    "    bias = np.random.rand()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        for input_data, target in zip(inputs, targets):\n",
    "            weighted_sum = np.dot(input_data, weights) + bias\n",
    "            output = linear_activation(weighted_sum)\n",
    "\n",
    "            error = target - output\n",
    "            weights += learning_rate * error * input_data\n",
    "            bias += learning_rate * error\n",
    "        \n",
    "    \n",
    "    def predict(input_data):\n",
    "        return linear_activation(np.dot(input_data, weights)) + bias\n",
    "    \n",
    "    def evaluate(inputs, targets):\n",
    "        prediction = [predict(input_data) for input_data in inputs]\n",
    "        mse = np.mean((prediction - target) ** 2)\n",
    "        return mse\n",
    "    \n",
    "    return predict, evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.27777777777777696, 0.25000000000000006, 0.27777777777777796, 0.8055555555555549]\n",
      "[0 0] -> -0.27777777777777696\n",
      "[0 1] -> 0.25000000000000006\n",
      "[1 0] -> 0.27777777777777796\n",
      "[1 1] -> 0.8055555555555549\n",
      "0.688657407407407\n"
     ]
    }
   ],
   "source": [
    "and_input = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "and_target = np.array([0, 0, 0, 1])\n",
    "\n",
    "and_predict, and_evaluate = SLP(and_input, and_target)\n",
    "\n",
    "predicted_values = [and_predict(input_data) for input_data in and_input]\n",
    "mse_score = and_evaluate(and_input, and_target)\n",
    "\n",
    "print(predicted_values)\n",
    "for input_data in and_input:\n",
    "    prediction = and_predict(input_data)\n",
    "    print(f\"{input_data} -> {prediction}\")\n",
    "\n",
    "print(mse_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
